{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "616b14af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\dell\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=GoogLeNet_Weights.IMAGENET1K_V1`. You can also use `weights=GoogLeNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'GradCAMpp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Create an instance of the GradCAM and GradCAM++ library\u001b[39;00m\n\u001b[0;32m     19\u001b[0m gradcam \u001b[38;5;241m=\u001b[39m GradCAM(model, target_layer)\n\u001b[1;32m---> 20\u001b[0m gradcam_pp \u001b[38;5;241m=\u001b[39m GradCAMpp(model, target_layer)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Load and preprocess an input image\u001b[39;00m\n\u001b[0;32m     23\u001b[0m input_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mVt\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m250.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'GradCAMpp' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pytorch_grad_cam import GradCAM\n",
    "#from grad-cam import GradCAM, GradCAMpp\n",
    "from torchvision import transforms\n",
    "\n",
    "# Load the pre-trained GoogleNet model\n",
    "model = models.googlenet(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Get the last convolutional layer of the model\n",
    "#target_layer = model.inception5b.branch0.double_conv_3x3.conv\n",
    "target_layer = [model.inception5b.branch4]# Choose the target layer for visualization\n",
    "\n",
    "\n",
    "# Create an instance of the GradCAM and GradCAM++ library\n",
    "gradcam = GradCAM(model, target_layer)\n",
    "gradcam_pp = GradCAMpp(model, target_layer)\n",
    "\n",
    "# Load and preprocess an input image\n",
    "input_image_path = 'E:\\\\Vt\\\\250.jpg'\n",
    "input_image = cv2.imread(input_image_path, 1)\n",
    "input_image = cv2.resize(input_image, (224, 224))\n",
    "input_tensor = transforms.ToTensor()(input_image).unsqueeze(0)\n",
    "\n",
    "# Normalize the input tensor\n",
    "#mean = [0.485, 0.456, 0.406]\n",
    "#std = [0.229, 0.224, 0.225]\n",
    "#input_tensor = transforms.Normalize(mean, std)(input_tensor)\n",
    "preprocess = transforms.Compose([\n",
    "        #transforms.Resize(256),\n",
    "        transforms.Resize((1024, 1024)),\n",
    "        #transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "input_tensor = preprocess(image)\n",
    "input_tensor = input_tensor.unsqueeze(0)\n",
    "\n",
    "# Generate the heatmap for GradCAM and GradCAM++\n",
    "heatmap = gradcam(input_tensor)\n",
    "heatmap_pp = gradcam_pp(input_tensor)\n",
    "\n",
    "# Convert the heatmap to a numpy array\n",
    "heatmap = heatmap[0, :, :].data.cpu().numpy()\n",
    "heatmap = np.maximum(heatmap, 0)\n",
    "heatmap /= np.max(heatmap)\n",
    "\n",
    "heatmap_pp = heatmap_pp[0, :, :].data.cpu().numpy()\n",
    "heatmap_pp = np.maximum(heatmap_pp, 0)\n",
    "heatmap_pp /= np.max(heatmap_pp)\n",
    "\n",
    "# Resize the input image and overlay the heatmap\n",
    "heatmap = cv2.resize(heatmap, (input_image.shape[1], input_image.shape[0]))\n",
    "heatmap = np.uint8(255 * heatmap)\n",
    "heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "result = heatmap * 0.3 + input_image * 0.5\n",
    "\n",
    "# Display the original image, GradCAM heatmap, and GradCAM++ heatmap\n",
    "cv2.imshow('Original Image', input_image)\n",
    "cv2.imshow('GradCAM Heatmap', heatmap)\n",
    "cv2.imshow('GradCAM++ Heatmap', heatmap_pp)\n",
    "cv2.imshow('Result', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87042f96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
